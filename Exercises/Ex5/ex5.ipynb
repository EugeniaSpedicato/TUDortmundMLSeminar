{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise 5 - Convolutional Neural Networks and the MNIST dataset\n",
    "This exercise is based on https://github.com/leriomaggio/deep-learning-keras-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We want to solve the same multinomial classification problem as in last weeks <a href=\"https://github.com/nackenho/TUDortmundMLSeminar/blob/master/Exercises/Ex4/ex4_sol.ipynb\"> exercise 4 </a> using the MNIST dataset, but this time we want to use a convolutional neural network for it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, we define a few useful functions, which we used in exercise 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################################### \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_history(network_history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.plot(network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(network_history.history['acc'])\n",
    "    plt.plot(network_history.history['val_acc'])\n",
    "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "###################################################################################################    \n",
    "\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "################################################################################################### \n",
    "import matplotlib.cm as cm\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)), cmap=cm.Greys, interpolation='nearest')\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "            \n",
    "################################################################################################### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Important: \n",
    "When dealing with images & convolutions, you need to handle the `image_data_format` properly, i.e. is the channel given first or last. The channel axis is an additional dimension of the input data used to access different views of the date, e.g. red/green/blue of a color image, left or right of a stereo sound file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    shape_ord = (1, img_rows, img_cols)\n",
    "else:  # channel_last\n",
    "    shape_ord = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data preprocessing\n",
    "* Load the mnist data of the keras datasets\n",
    "* Scale the design matrix to values between 0 and 1\n",
    "* Convert the design matrix to the expected (60000, 28, 28, 1) shape\n",
    "* Convert the target vector to one-hot-vectors for the 10 classes\n",
    "* Split the training data into 70% training and 30% validation data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and Normalise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A simple convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Convolution2D\n",
    "\n",
    "```python\n",
    "from keras.layers.convolutional import Conv2D\n",
    "\n",
    "Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', \n",
    "       data_format=None, dilation_rate=(1, 1), activation=None, \n",
    "       use_bias=True, kernel_initializer='glorot_uniform', \n",
    "       bias_initializer='zeros', kernel_regularizer=None, \n",
    "       bias_regularizer=None, activity_regularizer=None, \n",
    "       kernel_constraint=None, bias_constraint=None)\n",
    "```\n",
    "\n",
    "#### Arguments:\n",
    "\n",
    "<ul>\n",
    "<li><strong>filters</strong>: Integer, the dimensionality of the output space\n",
    "    (i.e. the number output of filters in the convolution).</li>\n",
    "<li><strong>kernel_size</strong>: An integer or tuple/list of 2 integers, specifying the\n",
    "    width and height of the 2D convolution window.\n",
    "    Can be a single integer to specify the same value for\n",
    "    all spatial dimensions.</li>\n",
    "<li><strong>strides</strong>: An integer or tuple/list of 2 integers,\n",
    "    specifying the strides of the convolution along the width and height.\n",
    "    Can be a single integer to specify the same value for\n",
    "    all spatial dimensions.\n",
    "    Specifying any stride value != 1 is incompatible with specifying\n",
    "    any <code>dilation_rate</code> value != 1.</li>\n",
    "<li><strong>padding</strong>: one of <code>\"valid\"</code> or <code>\"same\"</code> (case-insensitive).</li>\n",
    "<li><strong>data_format</strong>: A string,\n",
    "    one of <code>channels_last</code> (default) or <code>channels_first</code>.\n",
    "    The ordering of the dimensions in the inputs.\n",
    "    <code>channels_last</code> corresponds to inputs with shape\n",
    "    <code>(batch, height, width, channels)</code> while <code>channels_first</code>\n",
    "    corresponds to inputs with shape\n",
    "    <code>(batch, channels, height, width)</code>.\n",
    "    It defaults to the <code>image_data_format</code> value found in your\n",
    "    Keras config file at <code>~/.keras/keras.json</code>.\n",
    "    If you never set it, then it will be \"channels_last\".</li>\n",
    "<li><strong>dilation_rate</strong>: an integer or tuple/list of 2 integers, specifying\n",
    "    the dilation rate to use for dilated convolution.\n",
    "    Can be a single integer to specify the same value for\n",
    "    all spatial dimensions.\n",
    "    Currently, specifying any <code>dilation_rate</code> value != 1 is\n",
    "    incompatible with specifying any stride value != 1.</li>\n",
    "<li><strong>activation</strong>: Activation function to use\n",
    "    (see <a href=\"https://keras.io/activations/\">activations</a>).\n",
    "    If you don't specify anything, no activation is applied\n",
    "    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>\n",
    "<li><strong>use_bias</strong>: Boolean, whether the layer uses a bias vector.</li>\n",
    "<li><strong>kernel_initializer</strong>: Initializer for the <code>kernel</code> weights matrix\n",
    "    (see <a href=\"https://keras.io/initializers/\">initializers</a>).</li>\n",
    "<li><strong>bias_initializer</strong>: Initializer for the bias vector\n",
    "    (see <a href=\"https://keras.io/initializers/\">initializers</a>).</li>\n",
    "<li><strong>kernel_regularizer</strong>: Regularizer function applied to\n",
    "    the <code>kernel</code> weights matrix\n",
    "    (see <a href=\"https://keras.io/regularizers/\">regularizer</a>).</li>\n",
    "<li><strong>bias_regularizer</strong>: Regularizer function applied to the bias vector\n",
    "    (see <a href=\"https://keras.io/regularizers/\">regularizer</a>).</li>\n",
    "<li><strong>activity_regularizer</strong>: Regularizer function applied to\n",
    "    the output of the layer (its \"activation\").\n",
    "    (see <a href=\"https://keras.io/regularizers/\">regularizer</a>).</li>\n",
    "<li><strong>kernel_constraint</strong>: Constraint function applied to the kernel matrix\n",
    "    (see <a href=\"https://keras.io/constraints/\">constraints</a>).</li>\n",
    "<li><strong>bias_constraint</strong>: Constraint function applied to the bias vector\n",
    "    (see <a href=\"https://keras.io/constraints/\">constraints</a>).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -- Initializing the values for the convolution neural network\n",
    "\n",
    "nb_epoch = 2  # kept very low! Please increase if you can use a GPU\n",
    "\n",
    "batch_size = 256\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(nb_filters, kernel_size=(nb_conv, nb_conv), padding='valid', activation='relu', \n",
    "                 input_shape=shape_ord))  # note: the very first layer **must** always specify the input_shape\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, \n",
    "                 epochs=nb_epoch, verbose=1, \n",
    "                 validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Evaluating - Define an `evaluate` function, with the following properties:\n",
    "* It takes X_test and Y_test as arguments\n",
    "* It calculates the loss, the accuracy and the classification report \n",
    "* It plots the probability of being a zero for true zeros (red) and non-zeros (blue)\n",
    "* It computes and plots the confusion matrix\n",
    "* It plots the image, the prediction and the true value for the top 6 errors\n",
    "* It plots image and predictions for the first 15 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "### Your function\n",
    "def evaluate():\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adding more Dense Layers and Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Adding additional classification layers\n",
    "* Add a dense layer between the flatten layer and the output layer \n",
    "* Add a 25% dropout layer before the flatten layer\n",
    "* Add a 50% dropout layer between the two dense layers\n",
    "* Build the model, train the NN, plot the loss and accuracy evolution\n",
    "* Evaluate the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adding an additional convolution layer and a pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Adding additional classification layers\n",
    "* Add another `Conv2D` layer after the first convolutional layer with 64 filter, 3x3 kernel and `valid` padding\n",
    "* Add another `MaxPooling2D` layer with a 2x2 pooling size \n",
    "* Build the model, train the NN, plot the loss and accuracy evolution\n",
    "* Evaluate the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Understanding Convolutional Layers Structure\n",
    "\n",
    "We will inspect and understand the convolutional layer of our previously defined quite shallow CNN, which contains two [Convolution, Convolution, MaxPooling] stages, and two Dense layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding layer shapes\n",
    "\n",
    "An important feature of Keras layers is that each of them has an `input_shape` attribute, which you can use to visualize the shape of the input tensor, and an `output_shape` attribute, for inspecting the shape of the output tensor.\n",
    "\n",
    "As we can see, the input shape of the first convolutional layer corresponds to the `input_shape` attribute (which must be specified by the user). \n",
    "\n",
    "In this case, it is a `28x28` image with three color channels. \n",
    "\n",
    "Since this convolutional layer has the `padding` set to `same`, its output width and height will remain the same, and the number of output channel will be equal to the number of filters learned by the layer, 16. \n",
    "\n",
    "The following convolutional layer, instead, have the default `padding`, and therefore reduce width and height by $(k-1)$, where $k$ is the size of the kernel. \n",
    "\n",
    "`MaxPooling` layers, instead, reduce width and height of the input tensor, but keep the same number of channels. \n",
    "\n",
    "`Activation` layers, of course, don't change the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print (\"Layer\", i, \"\\t\", layer.name, \"\\t\\t\", layer.input_shape, \"\\t\", layer.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding weights shape\n",
    "\n",
    "In the same way, we can visualize the shape of the weights learned by each layer. \n",
    "\n",
    "In particular, Keras lets you inspect weights by using the `get_weights` method of a layer object. \n",
    "\n",
    "This will return a list with two elements, the first one being the **weight tensor** and the second one being the **bias vector**.\n",
    "\n",
    "In particular:\n",
    "\n",
    "- **MaxPooling layer** don't have any weight tensor, since they don't have learnable parameters. \n",
    "\n",
    "\n",
    "- **Convolutional layers**, instead, learn a $(n_o, n_i, k, k)$ weight tensor, where $k$ is the size of the kernel, $n_i$ is the number of channels of the input tensor, and $n_o$ is the number of filters to be learned. \n",
    "\n",
    "For each of the $n_o$ filters, a bias is also learned. \n",
    "\n",
    "\n",
    "- **Dense layers** learn a $(n_i, n_o)$ weight tensor, where $n_o$ is the output size and $n_i$ is the input size of the layer. Each of the $n_o$ neurons also has a bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    if len(layer.get_weights()) > 0:\n",
    "        W, b = layer.get_weights()\n",
    "        print(\"Layer\", i, \"\\t\", layer.name, \"\\t\\t\", W.shape, \"\\t\", b.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
