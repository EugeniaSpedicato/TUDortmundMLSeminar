{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 2 - Introduction to (Deep) Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise uses some images and information from https://github.com/YaleATLAS/CERNDeepLearningTutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [1 Introduction to Keras](#Introduction-to-Keras)\n",
    "* [2 Breast cancer dataset](#Breast-cancer-dataset)\n",
    "    * [Loading the dataset](#Loading-the-dataset)\n",
    "    * [Plotting the dataset](#Plotting-the-dataset)\n",
    "    * [Preparing the dataset](#Preparing-the-dataset)\n",
    "* [3 Training a dense neural network](#3Training-a-dense-neural-network)\n",
    "    * [Neural network model](#Neural-network-model)\n",
    "    * [Build a simple neural network](#Build-a-simple-neural-network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <a href='http://keras.io'><img src='https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png' style=\"height:100px;\"></a>\n",
    " *  Modular, powerful and intuitive Deep Learning Python library built on\n",
    " <center>\n",
    " <a href='http://deeplearning.net/software/theano/'><img src='./images/theano-logo.png' style=\"height:50px; display:inline;\"></a> and\n",
    " <a href='https://www.tensorflow.org/'><img src='./images/tf-logo.png' style=\"height:60px; display:inline\"></a> and\n",
    " <a href='https://docs.microsoft.com/en-us/cognitive-toolkit/'><img src='https://developer.nvidia.com/sites/default/files/akamai/cuda/images/deeplearning/cntk.png' style=\"height:80px; display:inline\"></a>\n",
    " </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> <i>Developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research. </i>\n",
    "<div align=\"right\">\n",
    "  https://keras.io\n",
    "</div>\n",
    "\n",
    "*  Minimalist, user-friendly interface\n",
    "*  Extremely well documented, lots of <a href='https://github.com/fchollet/keras/tree/master/examples'>working examples</a>\n",
    "*  Very shallow learning curve $\\rightarrow$ by far one of the best tools for both beginners and experts\n",
    "*  Open-source, developed and maintained by a community of contributors, and publicly hosted on <a href='https://github.com/fchollet/keras'>GitHub</a>\n",
    "*  Extensible: possibility to customize layers\n",
    " \n",
    "From the Keras website: \n",
    "<img src='./images/keras_principles.jpg' style=\"width:800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Breast cancer dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: For this exercise we want to use the breast cancer dataset from sci-kit learn. Prepare the dataset in the following way:\n",
    "* Load the dataset (`load_breast_cancer`), inspect it and create a pandas `DataFrame`.\n",
    "* How many example and how many features do we have? What are the names of the classes? How many examples of each class do we have?\n",
    "* Plot the mean radius and the mean smoothness of the training data in a 2D scatter plot for the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has also some nice built-in plotting features, for instance you can plot the histograms of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[breast_cancer.feature_names[0:10]].hist(alpha=0.8, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we are interested in the different shape between the two classes? We could simply add the target to the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(target=breast_cancer.target)\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then use the useful groupby function and plot a kernel density estimate (kde) plot: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"target\")[\"mean radius\"].plot(kind='kde', figsize=(10, 10))\n",
    "plt.legend(['malignant', 'benign'], loc='upper right')\n",
    "plt.xlabel('mean radius')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we could also plot the histogram: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"target\")[\"mean radius\"].hist(fill=False, figsize=(10, 10))\n",
    "plt.legend(['malignant', 'benign'], loc='upper right')\n",
    "plt.xlabel('mean radius')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a DataFrame you can even plot the full scatter plot matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(df[breast_cancer.feature_names[0:10]], c=breast_cancer.target, alpha=0.8, figsize=(20, 20), s=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the input features seem highly correlated, so it usually makes sense to quantify their correlation to the other features.\n",
    "We will now use seaborn: statistical data visualization to obtain the (linear) correlations between the input features.\n",
    "\n",
    "https://seaborn.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df[breast_cancer.feature_names[0:10]].corr(), annot=True, square=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like scikit-learn, Keras, takes as inputs the following objects:\n",
    " *  <h3>Design matrix $X$</h3>\n",
    " an `ndarray` of dimensions `[nb_examples, nb_features]` containing the distributions to be used as inputs to the model. Each row is an object to classify, each column corresponds to a specific variable.\n",
    " *  <h3>Target vector $y$</h3>\n",
    " an `array` of dimensions `[nb_examples]` containing the truth labels indicating the class each object belongs to (for classification), or the continuous target values (for regression).\n",
    " *  <h3>Weight vector $w$</h3> \n",
    " (optional) an `array` of dimensions `[nb_examples]` containing the weights to be assigned to each example\n",
    " \n",
    "The indices of these objects must map to the same examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Create design matrix and target vector for the first 10 features. Split the data into 70% training data and 30% testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common practice to scale the inputs to neural nets such that they have approximately similar ranges. Without this step, you might end up with variables whose values span very different orders of magnitude. This will create problems in the NN convergence due to very wild fluctuations in the magnitude of the internal weights. To take care of the scaling, we use the `sklearn` `StandardScaler`:\n",
    "<a href='http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html'><img src='./images/standardscaler.jpg' style=\"width:800px\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Training a dense neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer structure\n",
    " * Densely connected layer, where all inputs are connected to all outputs\n",
    " *  Linear transformation of the input vector $x \\in \\mathbb{R}^n$, which can be expressed using the $n \\times m$ matrix $W \\in \\mathbb{R}^{n \\times m}$ as:\n",
    "<center> $u = Wx + b$ </center>\n",
    "where $b \\in \\mathbb{R}^m$ is the bias unit\n",
    "\n",
    " *  All entries in both $W$ and $b$ are trainable\n",
    " *  In Keras:\n",
    " ```\n",
    "keras.layers.Dense(\n",
    "                    units,\n",
    "                    activation=None,\n",
    "                    use_bias=True,\n",
    "                    kernel_initializer='glorot_uniform',\n",
    "                    bias_initializer='zeros', kernel_regularizer=None,\n",
    "                    bias_regularizer=None,\n",
    "                    activity_regularizer=None,\n",
    "                    kernel_constraint=None,\n",
    "                    bias_constraint=None\n",
    ")\n",
    "```\n",
    "\n",
    " *  `input_dim` (or `input_shape`) are necessary arguments for the 1st layer of the net:\n",
    "\n",
    "```python\n",
    "# as first layer in a sequential model:\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(16,)))\n",
    "# now the model will take as input arrays of shape (*, 16)\n",
    "# and output arrays of shape (*, 32)\n",
    "\n",
    "# after the first layer, you don't need to specify\n",
    "# the size of the input anymore:\n",
    "model.add(Dense(32))\n",
    " ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    " *  Mathematical way of quantifying the activation state of a node $\\rightarrow$ whether it's firing or not\n",
    " *  Non-linear activation functions are the key to Deep Learning\n",
    " *  Allow NNs to learn complex, non-linear transformations of the inputs\n",
    " *  Some popular choices:\n",
    " <img src='./images/activations_table.jpg' style='width:700px'>\n",
    " <img src='./images/activation.jpg' style='width:800px'>\n",
    " Available activations (https://keras.io/activations/#available-activations):\n",
    "* **softmax**, **elu**, **selu**, **softplus**, **softsign**, **relu**, **tanh**, **sigmoid**, **hard_sigmoid**, **linear**\n",
    "\n",
    " Advanced Activation (https://keras.io/layers/advanced-activations/):\n",
    "* **LeakyReLU**, **PReLU**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions\n",
    "* Mathematical way of quantifying how much ŷ deviates from y\n",
    "* Dictates how strongly we penalize certain types of mistakes\n",
    "* Cost of inaccurately classifying an event\n",
    "* Many loss functions available in kears (https://keras.io/losses/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/loss.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=11, activation='relu', input_dim=10))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.image as mpimg\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that is a rather simple model, but let's define a loss function, an optimizer, a performance metric and compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the model, we pass the training data to the fit function. However, part of the training data will be used as validation data, which is used during the training to evaluate the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "history= model.fit(X_train, y_train, validation_split=0.3, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training process we have saved the loss and the accuracy of the training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the loss evolution over the training epochs for the training and validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can plot the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the loss and accuracy on our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test, batch_size=8)\n",
    "print loss_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict classes for our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing...'\n",
    "y_pred = model.predict(X_test, verbose = True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Plot the output prediction for malignant and benign breast cancer showing the separation between these two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we decide now to which class the test example needs to assigned based on our prediction? Intuitively, we could simply convert our predictions into classes by using a threshold of 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cls=np.where(y_pred > 0.5, 1, 0)\n",
    "print y_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cls = model.predict_classes(X_test, batch_size=1)\n",
    "print y_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Use the scikit learn metrics to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use scikit learn also to plot the ROC curve and calculate the AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred.ravel())\n",
    "auc = auc(fpr, tpr)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='NN (area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 5 (Bonus): Change the neural network model and study the impact on the performance\n",
    "* Make the neural network wider\n",
    "* Make the neural network deeper\n",
    "* Change the activation function of the hidden nodes\n",
    "* Change the activation function of the output node\n",
    "* Change the loss function, which ones are allowed?\n",
    "* Which neural network gives the best performance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
